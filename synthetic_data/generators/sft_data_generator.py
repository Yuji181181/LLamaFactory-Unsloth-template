"""
SFTç”¨åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€LLM APIã‚’ä½¿ç”¨ã—ã¦SFTç”¨ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
å®Ÿéš›ã®ã‚³ãƒ³ãƒšã§ã¯ã€ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¦ãã ã•ã„ã€‚
"""

import json
import os
from pathlib import Path
from typing import List, Dict
import argparse


def generate_sft_data_with_llm(
    num_samples: int = 100,
    api_key: str = None,
    model: str = "gpt-4",
) -> List[Dict]:
    """
    LLM APIã‚’ä½¿ç”¨ã—ã¦SFTç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    Args:
        num_samples: ç”Ÿæˆã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
        api_key: API ã‚­ãƒ¼
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    # æ³¨: å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€OpenAI APIã€Claude APIã€ã¾ãŸã¯ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’ä½¿ç”¨
    # ã“ã“ã§ã¯ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦ã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    print(f"ğŸ“ {num_samples}å€‹ã®SFTã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆä¸­...")
    
    data = []
    
    # ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    # å®Ÿéš›ã®ã‚³ãƒ³ãƒšã§ã¯ã€ã‚¿ã‚¹ã‚¯ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­è¨ˆ
    sample_instructions = [
        "æ¬¡ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚",
        "æ¬¡ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚",
        "æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚",
        "æ¬¡ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚",
    ]
    
    for i in range(num_samples):
        # ã“ã“ã§å®Ÿéš›ã«ã¯LLM APIã‚’å‘¼ã³å‡ºã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        # ä¾‹: response = openai.ChatCompletion.create(...)
        
        instruction = sample_instructions[i % len(sample_instructions)]
        
        data.append({
            "instruction": instruction,
            "input": f"ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ› {i+1}",
            "output": f"ã‚µãƒ³ãƒ—ãƒ«å‡ºåŠ› {i+1}ï¼ˆå®Ÿéš›ã«ã¯LLMãŒç”Ÿæˆï¼‰"
        })
        
        if (i + 1) % 10 == 0:
            print(f"  é€²æ—: {i+1}/{num_samples}")
    
    print(f"âœ… {len(data)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆå®Œäº†")
    return data


def generate_sft_data_with_templates(
    num_samples: int = 100,
    templates_file: str = None,
) -> List[Dict]:
    """
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã§SFTç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    Args:
        num_samples: ç”Ÿæˆã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
        templates_file: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    print(f"ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰{num_samples}å€‹ã®SFTã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆä¸­...")
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä¾‹
    # å®Ÿéš›ã®ã‚³ãƒ³ãƒšã§ã¯ã€ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨
    templates = [
        {
            "instruction": "æ¬¡ã®æ•°å­¦ã®å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„ã€‚",
            "input_template": "{a} + {b} = ?",
            "output_template": "{a} + {b} = {result}",
        },
        {
            "instruction": "æ¬¡ã®æ–‡ç« ã‚’ä¸å¯§èªã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚",
            "input_template": "{casual_text}",
            "output_template": "{polite_text}",
        },
    ]
    
    data = []
    
    for i in range(num_samples):
        template = templates[i % len(templates)]
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å€¤ã‚’åŸ‹ã‚è¾¼ã‚€
        # å®Ÿéš›ã«ã¯ãƒ©ãƒ³ãƒ€ãƒ ãªå€¤ã‚„ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã—ãŸå€¤ã‚’ä½¿ç”¨
        if "a" in template["input_template"]:
            import random
            a = random.randint(1, 100)
            b = random.randint(1, 100)
            result = a + b
            
            data.append({
                "instruction": template["instruction"],
                "input": template["input_template"].format(a=a, b=b),
                "output": template["output_template"].format(a=a, b=b, result=result)
            })
        else:
            data.append({
                "instruction": template["instruction"],
                "input": f"ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ› {i+1}",
                "output": f"ã‚µãƒ³ãƒ—ãƒ«å‡ºåŠ› {i+1}"
            })
    
    print(f"âœ… {len(data)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆå®Œäº†")
    return data


def split_train_val(data: List[Dict], val_ratio: float = 0.1) -> tuple:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã¨æ¤œè¨¼ã‚»ãƒƒãƒˆã«åˆ†å‰²
    
    Args:
        data: å…¨ãƒ‡ãƒ¼ã‚¿
        val_ratio: æ¤œè¨¼ã‚»ãƒƒãƒˆã®å‰²åˆ
    
    Returns:
        (train_data, val_data)
    """
    import random
    random.shuffle(data)
    
    split_idx = int(len(data) * (1 - val_ratio))
    train_data = data[:split_idx]
    val_data = data[split_idx:]
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°={len(train_data)}, æ¤œè¨¼={len(val_data)}")
    
    return train_data, val_data


def save_data(data: List[Dict], output_path: str):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    
    Args:
        data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {output_path} ({len(data)}ã‚µãƒ³ãƒ—ãƒ«)")


def main():
    parser = argparse.ArgumentParser(description='SFTç”¨åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ')
    parser.add_argument('--num_samples', type=int, default=100, help='ç”Ÿæˆã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°')
    parser.add_argument('--method', choices=['llm', 'template'], default='template', 
                        help='ç”Ÿæˆæ–¹æ³•ï¼ˆllm: LLM APIä½¿ç”¨, template: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½¿ç”¨ï¼‰')
    parser.add_argument('--val_ratio', type=float, default=0.1, help='æ¤œè¨¼ã‚»ãƒƒãƒˆã®å‰²åˆ')
    parser.add_argument('--output_dir', type=str, default='../synthetic_data/processed',
                        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸš€ SFTç”¨åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’é–‹å§‹")
    print("=" * 60)
    print(f"ç”Ÿæˆæ–¹æ³•: {args.method}")
    print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {args.num_samples}")
    print(f"æ¤œè¨¼ã‚»ãƒƒãƒˆå‰²åˆ: {args.val_ratio}")
    print("")
    
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    if args.method == 'llm':
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            print("âš ï¸  è­¦å‘Š: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("   ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
            data = generate_sft_data_with_templates(args.num_samples)
        else:
            data = generate_sft_data_with_llm(args.num_samples, api_key)
    else:
        data = generate_sft_data_with_templates(args.num_samples)
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ã‚»ãƒƒãƒˆã«åˆ†å‰²
    train_data, val_data = split_train_val(data, args.val_ratio)
    
    # ä¿å­˜
    save_data(train_data, f"{args.output_dir}/sft_train.json")
    save_data(val_data, f"{args.output_dir}/sft_val.json")
    
    # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜ï¼ˆJSONLå½¢å¼ï¼‰
    raw_path = f"{args.output_dir}/../raw/sft_raw.jsonl"
    Path(raw_path).parent.mkdir(parents=True, exist_ok=True)
    with open(raw_path, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    print(f"ğŸ’¾ ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {raw_path}")
    
    print("")
    print("=" * 60)
    print("âœ… SFTç”¨åˆæˆãƒ‡ãƒ¼ã‚¿ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("=" * 60)
    print("")
    print("ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯:")
    print(f"     python synthetic_data/quality_check/check_sft_data.py")
    print("")
    print("  2. LLaMA-Factoryã®ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼:")
    print(f"     cp {args.output_dir}/sft_train.json LLaMA-Factory/data/competition_sft/train.json")
    print(f"     cp {args.output_dir}/sft_val.json LLaMA-Factory/data/competition_sft/val.json")
    print("")
    print("  3. SFTãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ:")
    print("     cd LLaMA-Factory && llamafactory-cli train ../configs/sft_config.yaml")
    print("")


if __name__ == "__main__":
    main()
